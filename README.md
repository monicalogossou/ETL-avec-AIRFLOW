# 📦 Automatisation d'un pipeline ETL avec Apache Airflow


## ✅ Objectifs réalisés

1. Automatiser un workflow ETL simple

2. Manipuler et transformer des fichiers texte

3. Orchestrer les étapes avec Apache Airflow

4. Gérer les DAGs avec Airflow CLI

5. Mettre en place une solution de traitement automatisée


## 📁 Structure
- `First_Dag.py` un workflow ETL simple avec PythoOperator
- `Airflow.py` quelques commandes d'Airflow
- `dagwithbashcode.py` un workflow ETL simple avec BashOperator
- `etl_acces_log.py` un Pipeline complet avec PythonOperator
- `etl_acces_logwith bashcode` un Pipeline complet avec BashOperator
- `README.md` : Ce fichier

---

🎓 Ce projet me permet de Concevoir, automatiser et gérer un pipeline ETL simple en utilisant Apache Airflow, 
avec des étapes de traitement de fichiers (locaux et distants), orchestrées avec des opérateurs Python et Bash, 
tout en exploitant les outils de gestion de DAGs d’Airflow.
